基础知识就像是一座大楼的地基，它决定了我们的技术高度。而要想快速做出点事情，前提条件一定是基础能力过硬，“内功”要到位

越是厉害的公司，越是注重考察数据结构与算法这类基础知识。相比短期能力，他们更看中你的长期潜力。

作为业务开发，我们会用到各种框架、中间件和底层系统，比如 Spring、RPC 框架、消息中间件、Redis 等等。在这些基础框架中，一般都揉和了很多基础数据结构和算法的设计思想。

基础架构研发工程师，写出达到开源水平的框架才是你的目标！

高手之间的竞争其实就在细节。这些细节包括：你用的算法是不是够优化，数据存取的效率是不是够高，内存是不是够节省等等。这些累积起来，决定了一个框架是不是优秀。

何为编程能力强？是代码的可读性好、健壮？还是扩展性好？我觉得没法列，也列不全。但是，在我看来，性能好坏起码是其中一个非常重要的评判标准。

数据结构和算法是相辅相成的。数据结构是为算法服务的，算法要作用在特定的数据结构之上。

想要学习数据结构与算法，首先要掌握一个数据结构与算法中最重要的概念——复杂度分析。
数据结构和算法解决的是如何更省、更快地存储和处理数据的问题

学习要学会找重点

20 个最常用的、最基础数据结构与算法，不管是应付面试还是工作需要，只要集中精力逐一攻克这 20 个知识点就足够了。
这里面有 10 个数据结构：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie 树；10 个算法：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法。

在学习数据结构和算法的过程中，要学习它的“来历”“自身的特点”“适合解决的问题”以及“实际的应用场景”。
学习知识的过程是反复迭代、不断沉淀的过程。

只要讲到数据结构与算法，就一定离不开时间、空间复杂度分析

事后统计法:
1. 测试结果非常依赖测试环境
2. 测试结果受数据规模的影响很大

我们需要一个不用具体的测试数据来测试，就可以粗略地估计算法的执行效率的方法

所有代码的执行时间 T(n) 与每行代码的执行次数n成正比

	T(n) = O(f(n))

f(n) 表示每行代码执行的次数总和
公式中的O，表示代码的执行时间 T(n) 与 f(n) 表达式成正比。

大O时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势，所以，也叫作渐进时间复杂度（asymptotic time complexity），简称时间复杂度。

当 n 很大时，你可以把它想象成10000、100000。而公式中的低阶、常量、系数三部分并不左右增长趋势，所以都可以忽略。

- O(1)

- O(log n), O(nLog n)

		i = 1;
		while ( i <= n) {
			i = i * 2;
		}

log3n 就等于 log32 * log2n，所以 O(log3n) = O(C * log2n)，其中 C=log32 是一个常量。基于我们前面的一个理论：在采用大 O 标记复杂度的时候，可以忽略系数，即 O(Cf(n)) = O(f(n))。

- O(m+n), O(m*n)


时间复杂度的全称是渐进时间复杂度，表示算法的执行时间与数据规模之间的增长关系。
类比一下，空间复杂度全称就是渐进空间复杂度（asymptotic space complexity），表示算法的存储空间与数据规模之间的增长关系。



最好情况时间复杂度（best case time complexity）、
最坏情况时间复杂度（worst case time complexity）、
平均情况时间复杂度（average case time complexity）、
均摊时间复杂度（amortized time complexity）




数组

我们拿一个长度为 10 的 int 类型的数组 int[] a = new int[10] 来举例。例如计算机给数组 a[10]，分配了一块连续内存空间 1000～1039，其中，内存块的首地址为 base_address = 1000。

	a[i]_address = base_address + i * data_type_size


每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。



链表
一个经典的链表应用场景，那就是 LRU 缓存淘汰算法
缓存是一种提高数据读取性能的技术
缓存的大小有限，当缓存被用满时，哪些数据应该被清理出去，哪些数据应该被保留？这就需要缓存淘汰策略来决定。常见的策略有三种：先进先出策略 FIFO（First In，First Out）、最少使用策略 LFU（Least Frequently Used）、最近最少使用策略 LRU（Least Recently Used）。

单链表、双向链表和循环链表

双向链表需要额外的两个空间来存储后继结点和前驱结点的地址。所以，如果存储同样多的数据，双向链表要比单链表占用更多的内存空间。虽然两个指针比较浪费存储空间，但可以支持双向遍历，这样也带来了双向链表操作的灵活性。
从结构上来看，双向链表可以支持 O(1) 时间复杂度的情况下找到前驱结点

尽管单纯的删除操作时间复杂度是 O(1)，但遍历查找的时间是主要的耗时点，对应的时间复杂度为 O(n)。

用空间换时间的设计思想

当内存空间充足的时候，如果我们更加追求代码的执行速度，我们就可以选择空间复杂度相对较高、但时间复杂度相对很低的算法或者数据结构。相反，如果内存比较紧缺，比如代码跑在手机或者单片机上，这个时候，就要反过来用时间换空间的设计思路。

数组简单易用，在实现上使用的是连续的内存空间，可以借助CPU的缓存机制，预读数组中的数据，所以访问效率更高。
而链表在内存中并不是连续存储，所以对 CPU 缓存不友好，没办法有效预读。

数组的缺点是大小固定，一经声明就要占用整块连续内存空间。如果声明的数组过大，系统可能没有足够的连续内存空间分配给它，导致“内存不足（out of memory）”。如果声明的数组过小，则可能出现不够用的情况。这时只能再申请一个更大的内存空间，把原数组拷贝进去，非常费时。链表本身没有大小的限制，天然地支持动态扩容，我觉得这也是它与数组最大的区别。




栈

后进者先出，先进者后出，这就是典型的“栈”结构

用数组实现的栈，我们叫作顺序栈，用链表实现的栈，我们叫作链式栈。




队列

public boolean enqueue(String item) {
    // 
    if (tail == n) {
        if (head == 0) return false;

        for (int i = head; i < tail; ++i) {
            items[i-head] = items[i];
        }

        tail -= head;
        head = 0;
    }

    items[tail] = item;
    ++tail;

    return true;
}

在用数组实现的非循环队列中，队满的判断条件是 tail == n，队空的判断条件是 head == tail。
针对循环队列,队列为空的判断条件仍然是 head == tail。当队满时，(tail+1)%n=head
当队列满时，tail指向的位置实际上是没有存储数据的。所以，循环队列会浪费一个数组的存储空间。


阻塞队列和并发队列
阻塞队列其实就是在队列基础上增加了阻塞操作。简单来说，就是在队列为空的时候，从队头取数据会被阻塞。因为此时还没有数据可取，直到队列中有了数据才能返回；如果队列已经满了，那么插入数据的操作就会被阻塞，直到队列中有空闲位置后再插入数据，然后再返回。

线程安全的队列我们叫作并发队列。最简单直接的实现方式是直接在 enqueue()、dequeue() 方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或者取操作。实际上，基于数组的循环队列，利用 CAS 原子操作，可以实现非常高效的并发队列。这也是循环队列比链式队列应用更加广泛的原因。

高性能队列 Disruptor、Linux 环形缓存，都用到了循环并发队列；Java concurrent 并发包利用 ArrayBlockingQueue 来实现公平锁等。




递归







Redis 中，键的数据类型是字符串,值的数据类型有很多，常用的数据类型有这样几种，它们分别是字符串、列表、字典、集合、有序集合。



